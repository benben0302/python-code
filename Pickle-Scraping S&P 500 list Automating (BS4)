import bs4 as bs
import datetime as dt
import os
import pandas as pd
import pandas_datareader.data as web
import pickle #save object
import requests

###Grab data on the wiki and create a pickle to save it.
def save_sp500_tickers():
    #if (resp.text) doesn't seem to be returning the same page add below two lines
    #headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.27 Safari/537.17'}
    #resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies',headers=headers)
    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')
    soup = bs.BeautifulSoup(resp.text, 'lxml')
    table = soup.find('table', {'class': 'wikitable sortable'})
    tickers = []
    for row in table.findAll('tr')[1:]: #from 2ed tr(1st = [0:])
        ticker = row.findAll('td')[0].text #1st td
        ticker = ticker[:-1] #Eliminate /n sign
        tickers.append(ticker)
    
    with open("sp500tickers.pickle","wb") as f: #open a file
        pickle.dump(tickers,f) # put the dict into opened file
        
    return tickers
save_sp500_tickers() #save opened file #operate one time

--------------------------------------------------------

###Grab stock data on the yahoo and save into csv file
def get_data_from_yahoo(reload_sp500=False):
    if reload_sp500:
        tickers=save_sp500_tickers()
    else:
        with open("sp500tickers.pickle","rb") as f:
            tickers=pickle.load(f)
    if not os.path.exists('stock_dfs'):
        os.makedirs('stock_dfs') #create folder

    start=dt.datetime(2010,1,1)
    end=dt.datetime(2019,12,31)

    for ticker in tickers: #[:10] = 1-10
        print(ticker)
        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):
            try: # some company have some problem of dates dataframe 
                df=web.DataReader(ticker,'yahoo',start,end)
                df.to_csv('stock_dfs/{}.csv'.format(ticker))
            except KeyError:
                pass
        else:
            print('Already have{}'.format(ticker))
            
get_data_from_yahoo()

--------------------------------------------------------
###organize whole company's data into one file


def compile_data():
    with open("sp500tickers.pickle","rb") as f:
        tickers=pickle.load(f)
        
    main_df= pd.DataFrame()
    for count,ticker in enumerate(tickers): #enumerate=count all of names on the list
        try: 
            df=pd.read_csv("stock_dfs/{}.csv".format(ticker))
            df.set_index('Date',inplace=True)

            df.rename(columns={'Adj Close':ticker},inplace=True)
            df.drop(['Open','High','Low','Close','Volume'],1,inplace=True)

            if main_df.empty:
                main_df = df
            else:
                main_df =main_df.join(df, how='outer')
            if count % 10 == 0:
                print(count)
        except FileNotFoundError:
                pass
    
    print(main_df.head())
    main_df.to_csv('sp500_joined_closes.csv')
    
compile_data()

--------------------------------------------------------
### make a correation plot of whole sp500 companies



import matplotlib.pyplot as plt
from matplotlib import style
import numpy as np
%matplotlib qt

style.use('ggplot')
def visualize_data():
    df = pd.read_csv('sp500_joined_closes.csv')
        #df['AAPL'].plot()
        #plt.show()
    df_corr=df.corr()
    print(df_corr.head())
    
    data=df_corr.values
    fig=plt.figure()
    ax=fig.add_subplot(1,1,1) #heatplot
    
    heatmap=ax.pcolor(data,cmap=plt.cm.RdYlGn)
    fig.colorbar(heatmap)
    ax.set_xticks(np.arange(data.shape[0])+0.5,minor=False)
    ax.set_yticks(np.arange(data.shape[1])+0.5,minor=False)
    ax.invert_yaxis() #Yaxis up side down
    ax.xaxis.tick_top() #xaxis ticker move to the top
    
    column_labels=df_corr.columns
    row_labels=df_corr.index
    
    ax.set_xticklabels(column_labels)
    ax.set_yticklabels(row_labels)
    plt.xticks(rotation=90) #extend space of xaxis
    heatmap.set_clim(-1,1)
    plt.tight_layout #adjust the figure
    plt.show()
    
visualize_data()

--------------------------------------------------------
#Calculate future price direction from Past data.


import numpy as np
import pandas as pd
import pickle

def process_data_for_lables(ticker):
    hm_days=7
    df=pd.read_csv('sp500_joined_closes.csv')
    tickers=df.columns.values.tolist()
    df.fillna(0,inplace=True)
    
    for i in range(1,hm_days+1):
        df['{}_{}d'.format(ticker,i)]=(df[ticker].shift(-i)-df[ticker])/df[ticker] #future day - present day
        
    df.fillna(0,inplace=True) #fill na data
    return tickers,df
    

process_data_for_lables('AAPL')

--------------------------------------------------------
#strategies

def buy_sell_hold(*args):
    cols = [c for c in args]
    requirement = 0.02
    for col in cols:
        if col > requirement: #buy
            return 1
        if col < -requirement: #sell
            return -1
    return 0 #hold

--------------------------------------------------------
#Count buy & sell times 

from collections import Counter
def extract_featuresets(ticker):
    hm_days=7
    tickers, df = process_data_for_lables(ticker)
    df['{}_target'.format(ticker)]=list(map(buy_sell_hold, 
                                            *[df['{}_{}d'.format(ticker, i)]for i in range(1, hm_days+1)]))
                                            #map = give df['{}_{}d'.format(ticker, i) each column's data a buy_sell_hold function
    vals = df['{}_target'.format(ticker)].values.tolist() #list value
    str_vals = [str(i) for i in vals]
    print('Data spread:',Counter(str_vals)) #counter each number appear how many times
    
    df.fillna(0, inplace=True)
    df = df.replace([np.inf, -np.inf], np.nan)
    df.dropna(inplace=True)
    
    df_vals = df[[ticker for ticker in tickers]].set_index('Date').pct_change() #you should set index for avoiding str error.
    df_vals = df_vals.replace([np.inf, -np.inf], 0)
    df_vals.fillna(0, inplace=True)
                                        
    X = df_vals.values #pct_change()
    y = df['{}_target'.format(ticker)].values #o,1,-1
                                        
    return X,y,df 
                                           

#extract_featuresets('AAPL')

--------------------------------------------------------
###Machine learning training

from sklearn import svm, neighbors
#from sklearn.model_selection import cross_validate #Have to import cross_validate from model after V0.2
from sklearn.model_selection import train_test_split
from sklearn.ensemble import VotingClassifier, RandomForestClassifier
from warnings import simplefilter

simplefilter(action='ignore', category=FutureWarning)

def do_ml(ticker):
    X,y,df = extract_featuresets(ticker)
    
    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25)
    
    
    #clf = neighbors.KNeighborsClassifier()
    clf = VotingClassifier([('lsvc',svm.LinearSVC()), 
                            ('knn',neighbors.KNeighborsClassifier()),
                            ('rfor', RandomForestClassifier())])
    # FutureWarning to VotingClassifier                       
    clf.fit(X_train, y_train)
    
    confidence = clf.score(X_test, y_test)
    print('accuracy:',confidence)
    predictions = clf.predict(X_test)
    print('Predicited spread:', Counter(predictions))
    
    return confidence
    
do_ml('AAPL')



